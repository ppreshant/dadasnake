# GENERAL INFORMATION
raw_directory: "testdata"
# where all the raw data is kept (or linked to)
sample_table: "testdata/samples.small.tsv"
# a tab-separated table with at least the library name, name of the first (and second) read file
outputdir: "dadasnake_output"
# where all the output goes; each output directory can hold the results of one completed pipeline run only
paired: true
# set to false for single-end sequences, second read files will be ignored
tmp_dir: "tmp"
# by default, a folder for temporary files is created in the output directory
big_data: false
# set big_data to true, if you have several thousands of samples and can make use of big-mem computing nodes
email: ""
#  if your system can send emails, it will use this address to notify at the end of a run. Check spelling, it's not tested.

# STEPS
do_primers: true
# should primers be cut or polyG tails removed?
do_dada: true
# should DADA2 be run?
do_taxonomy: true
# should taxonomic classification be done? 
do_postprocessing: true
# should some more steps be done (e.g. functional annotation)
hand_off:
  biom: false
  phyloseq: true
# default output is tsv and RDS; get additional phyloseq object here

# PRIMER REMOVAL SETTINGS
primers:
  fwd: 
    sequence: GTGYCAGCMGCCGCGGTAA
    name: 515F
  rvs: 
    sequence: GGACTACNVGGGTWTCTAAT
    name: 806R
primer_cutting:
  overlap: 10
  count: 2
  filter_if_not_match: any
  perc_mismatch: 0.2
  indels: "--no-indels"
  both_primers_in_read: false
sequencing_direction: "unknown"
# can be unknown, fwd_1, or rvs_1 (fwd_1 means the first read contains the fwd primer)
nextseq_novaseq: false
# set to true, if data comes from 2-color chemistry to remove poly-G ends

# READ FILTERING SETTINGS (in DADA2)
filtering:
  trunc_length:
    fwd: 0
    rvs: 0
  trunc_qual: 
    fwd: 2
    rvs: 2
  max_EE:
    fwd: Inf
    rvs: Inf
  minLen:
    fwd: 20
    rvs: 20
  maxLen:
    fwd: Inf
    rvs: Inf
  minQ:
    fwd: 0
    rvs: 0
  maxN: 0
  rm_phix: true
  trim_left:
    fwd: 0
    rvs: 0

# DOWNSAMPLING CAN BE DONE BETWEEN READ FILTERING AND DADA2
downsampling:
  do: false
  number: 50000
  min: true
# if false, lower samples are kept?
  seed: 123
  use_total: false
  total: 100000000

# DADA2 SETTINGS
error_seed: 100
dada:
  band_size: 16
  homopolymer_gap_penalty: NULL
  pool: false
  omega_A: 1e-40
  priors: ""
  omega_P: 1e-4
  omega_C: 1e-40
  gapless: true
  selfConsist: false
  no_error_assumptions: false
  kdist_cutoff: 0.42
  match: 4
  mismatch: -5
  gap_penalty: -8
  errorEstimationFunction: loessErrfun
# classical options: PacBioErrfun or noqualErrfun
# alternatives are loessErrfun_mod1, loessErrfun_mod2, loessErrfun_mod3, loessErrfun_mod4
# see https://github.com/ErnakovichLab/dada2_ernakovichlab
  use_quals: true
  error_nbases: 1e8
  error_omega_C: 0
  error_max_consist: 10
pair_merging:
  min_overlap: 12
  max_mismatch: 0
  just_concatenate: false
  trim_overhang: true
chimeras:
  remove: true
  remove_by_run: false
  method: consensus
# can be consensus, pooled or per-sample
  minFoldParentOverAbundance: 2
  minParentAbundance: 8
  allowOneOff: false
  minOneOffParentDistance: 4
  maxShift: 16

# SETTINGS FOR TAXONOMIC ANNOTATION
taxonomy:
  dada:
    do: false
# classification is only done, if do_taxonomy is true
    run_on:
      - ASV
      - cluster
    post_ITSx: false
    db_path: "../DBs/DADA2"
    refFasta: "silva_nr99_v138_train_set.fa.gz"
    ref_dbs_full: ""
    db_short_names: "silva_v138_nr99"
    minBoot: 50 
    tryRC: false
    look_for_species: false
    seed: 101
    spec_db: "../DBs/DADA2/silva_species_assignment_v138.fa.gz"
  decipher:
    do: false
# classification is only done, if do_taxonomy is true
    run_on:
      - ASV
      - cluster
    post_ITSx: false
    db_path: "../DBs/decipher"
    tax_db: "SILVA_SSU_r138_2019.RData"
    ref_dbs_full: ""
    db_short_names: "SILVA_SSU_r138"
    threshold: 60
    strand: top
    bootstraps: 100
    seed: 100  
    look_for_species: false
    spec_db: "../DBs/DADA2/silva_species_assignment_v138.fa.gz"
  mothur:
    do: true
# classification is only done, if do_taxonomy is true
    run_on:
      - ASV
      - cluster
    post_ITSx: false
    db_path: "../DBs/mothur"
    tax_db: "SILVA_138_SSURef_NR99_prok.515F.806R"
    ref_dbs_full: ""
    db_short_names: "SILVA_138_SSURef_NR99_cut"
    cutoff: 60
    rank_number: 7
blast:
  do: true
# blast is only done, if do_taxonomy is true
  run_on:
    - ASV
    - cluster
  db_path: "../DBs/ncbi_16S_ribosomal_RNA"
  tax_db: 16S_ribosomal_RNA
  e_val: 0.01
  tax2id: ""
  all: true
  max_targets: 10
  run_basta: true
  basta_db: "../DBs/ncbi_taxonomy"
  basta_e_val: 0.00001
  basta_alen: 100
  basta_number: 0
  basta_min: 3
  basta_id: 80
  basta_besthit: true
  basta_perchits: 99
ITSx:
  do: false
# ITSx is only done, if do_taxonomy is true
  run_on:
    - ASV
    - cluster
  min_regions: 1
  region: ITS2
  e_val: 1e-5
  query_taxa: .
  target_taxon: F

# SETTINGS FOR CLUSTERING ASV TABLE AT e.g. 97%
post_clustering:
  do: true
# do is only used if no taxonomy is done to trigger clustering
  cutoff: 0.97
# similarity cut-off
  method: vsearch
# method can be vsearch or decipher  
  strand: plus
# strand only works for vsearch

# SETTINGS FOR POST-PROCESSING
final_table_filtering:
  do: true
# filtering is only done, if do_postprocessing is true
  keep_target_taxa: "."
# this should understand regular expression for R
  target_min_length: 1
  target_max_length: 10000
postprocessing:
  rarefaction_curve: true
  funguild:
    do: false
    funguild_db: "../DBs/functions/funguild_db.json"
    classifier_db: mothur.SILVA_138_SSURef_NR99_cut
  fungalTraits:
    do: false
    db: "../DBs/functions/FungalTraits_1.2_ver_16Dec_2020_V.1.2.tsv"
    classifier_db: mothur.SILVA_138_SSURef_NR99_cut
    level: "Genus"
  picrust2:
    do: true
    stratified: true
    per_sequence_contrib: true
    skip_norm: false
    max_nsti: 2
    do_nsti: true
    do_minpath: true
    do_gapfill: true
    do_coverage: false
    min_reads: 1
    min_samples: 1
    pathways: true
    placement_tool: "epa-ng"
#placement_tool can be epa-ng or sepp
    in_traits: "EC,KO"
#can be any combination of COG, EC, KO, PFAM, TIGRFAM (with just a comma, no space between)
    custom_trait_tables: ""
    marker_gene_table: ""
    pathway_map: ""
    reaction_func: ""
    regroup_map: ""
    hsp_method: "mp"
# can be one of mp,emp_prob,pic,scp,subtree_average
    edge_exponent: 0.5
    min_align: 0
  tax4fun2:
    do: false
# I can't really recommend running tax4fun2 at this moment, as the package is unavailable
    db: "../DBs/functions/Tax4Fun2_ReferenceData_v2"
    database_mode: "Ref99NR"
    normalize_by_copy_number: true 
    min_identity_to_reference: 0.97
    user_data: false
    user_dir: "../DBs/functions/GTDB_202_tax4fun2"
    user_db: "GTDB_fun"
  treeing:
    do: true
    fasttreeMP: ""
# you can add settings for fasttreeMP, which needs to be configured for specific HPCs

# DON'T TOUCH THESE SETTINGS:
sessionName: ""
# only read, if you're not using the dadasnake wrapper
normalMem: ""
# size of the RAM of one core of your normal copute nodes (e.g. 8G) | may be fixed during installation, only necessary for cluster submission, usually set via VARIABLE_CONFIG
bigMem: ""
# size of the RAM of one core of your high memory copute nodes (e.g. 30G) | may be fixed during installation, only necessary for cluster submission; usually set via VARIABLE_CONFIG
bigCores: ""
#  maximum number of high memory copute nodes to use (e.g. 4) | 0 means all nodes have the same (normal) size may be fixed during installation, only necessary for cluster submission
sessionKind: ""
# a string | all | automatically set by dadasnake wrapper | don't change
settingsLocked: false
# automatically set by dadasnake wrapper | it doesn't matter what you do - you can only change this in VARIABLE_CONFIG
